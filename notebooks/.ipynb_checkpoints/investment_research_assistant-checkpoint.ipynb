{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3536ce3b-fdcd-4782-ad4f-e4738a8443bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Investment Research Assistant Loaded!\n",
      "\n",
      "🔧 Setup Instructions:\n",
      "1. Set your API key: setup_api_key('your-openai-api-key-here')\n",
      "2. Run research: await run_research_example('AAPL')\n",
      "3. Or create custom query: query = create_research_query('MSFT', 'fundamental')\n",
      "\n",
      "💡 Available functions:\n",
      "- setup_api_key(api_key)\n",
      "- run_research_example(ticker)\n",
      "- create_research_query(ticker, query_type, time_horizon, risk_tolerance, questions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Run this in separate Jupyter cells:\\n\\n# Cell 1: Setup\\nsetup_api_key(\"your-openai-api-key-here\")\\n\\n# Cell 2: Run research  \\nresults, report = await run_research_example(\"AAPL\")\\n\\n# Cell 3: Custom research\\ncustom_query = create_research_query(\\n    ticker=\"MSFT\",\\n    query_type=\"fundamental\", \\n    questions=[\"How is the cloud business performing?\", \"What\\'s the AI strategy?\"]\\n)\\norchestrator = InvestmentResearchOrchestrator()\\ncustom_results = await orchestrator.conduct_research(custom_query)\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "AI-Powered Investment Research Assistant with Agentic RAG\n",
    "=======================================================\n",
    "\n",
    "This project demonstrates a multi-agent system for comprehensive investment analysis\n",
    "using RAG (Retrieval-Augmented Generation) architecture.\n",
    "\n",
    "Agents:\n",
    "1. Planning Agent - Breaks down complex research queries\n",
    "2. Data Collection Agent - Gathers information from multiple sources  \n",
    "3. Analysis Agent - Synthesizes findings and identifies patterns\n",
    "4. Risk Assessment Agent - Flags potential concerns and risks\n",
    "\n",
    "Author: [Your Name]\n",
    "GitHub: [Your GitHub URL]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def safe_json_serializer(obj):\n",
    "    \"\"\"Safe JSON serializer for pandas objects and datetime\"\"\"\n",
    "    if isinstance(obj, pd.Timestamp):\n",
    "        return obj.isoformat()\n",
    "    elif isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):\n",
    "        return None\n",
    "    return str(obj)\n",
    "def df_to_jsonable_records(df: Optional[pd.DataFrame]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Convert a DataFrame to a JSON-safe list-of-records with ISO date strings.\"\"\"\n",
    "    if df is None or (hasattr(df, \"empty\") and df.empty):\n",
    "        return []\n",
    "    out = df.copy()\n",
    "\n",
    "    # If the index is date-like, keep it as a column\n",
    "    if isinstance(out.index, (pd.DatetimeIndex, pd.PeriodIndex)):\n",
    "        out = out.reset_index()\n",
    "\n",
    "    # Also if columns are periods/datetimes, cast to str\n",
    "    out.columns = [str(c) for c in out.columns]\n",
    "\n",
    "    # Convert any datetime-like columns to ISO strings\n",
    "    for c in out.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(out[c]):\n",
    "            out[c] = out[c].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Replace NaN with None so JSON is clean\n",
    "    out = out.where(pd.notnull(out), None)\n",
    "    return out.to_dict(orient=\"records\")\n",
    "\n",
    "class AgentRole(Enum):\n",
    "    PLANNER = \"planning_agent\"\n",
    "    COLLECTOR = \"data_collection_agent\" \n",
    "    ANALYST = \"analysis_agent\"\n",
    "    RISK_ASSESSOR = \"risk_assessment_agent\"\n",
    "\n",
    "@dataclass\n",
    "class ResearchQuery:\n",
    "    \"\"\"Structure for investment research queries\"\"\"\n",
    "    ticker: str\n",
    "    query_type: str  # \"fundamental\", \"technical\", \"sentiment\", \"comprehensive\"\n",
    "    time_horizon: str  # \"short\", \"medium\", \"long\"\n",
    "    specific_questions: List[str]\n",
    "    risk_tolerance: str  # \"conservative\", \"moderate\", \"aggressive\"\n",
    "\n",
    "@dataclass\n",
    "class AgentResponse:\n",
    "    \"\"\"Structure for agent responses\"\"\"\n",
    "    agent_role: AgentRole\n",
    "    content: str\n",
    "    confidence: float\n",
    "    sources: List[str]\n",
    "    timestamp: datetime\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class BaseAgent:\n",
    "    \"\"\"Base class for all agents\"\"\"\n",
    "    \n",
    "    def __init__(self, role: AgentRole, llm_model: str = \"gpt-3.5-turbo\"):\n",
    "        self.role = role\n",
    "        \n",
    "        # Ensure API key is set before initializing LLM\n",
    "        if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "            raise ValueError(\n",
    "                \"OpenAI API key not found! Please run setup_api_key() first or set OPENAI_API_KEY environment variable.\"\n",
    "            )\n",
    "        \n",
    "        self.llm = ChatOpenAI(\n",
    "            model=llm_model, \n",
    "            temperature=0.1,\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        self.logger = logging.getLogger(f\"{role.value}\")\n",
    "        \n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        \"\"\"Abstract method to be implemented by each agent\"\"\"\n",
    "        raise NotImplementedError(\"Each agent must implement process method\")\n",
    "\n",
    "class PlanningAgent(BaseAgent):\n",
    "    \"\"\"Agent responsible for breaking down research queries into actionable tasks\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.PLANNER)\n",
    "        self.planning_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an expert investment research planner. Break down this investment research query \n",
    "        into specific, actionable sub-tasks for other specialized agents.\n",
    "\n",
    "        Query Details:\n",
    "        - Ticker: {ticker}\n",
    "        - Query Type: {query_type}\n",
    "        - Time Horizon: {time_horizon}\n",
    "        - Specific Questions: {specific_questions}\n",
    "        - Risk Tolerance: {risk_tolerance}\n",
    "\n",
    "        Create a detailed research plan with:\n",
    "        1. Priority-ordered tasks for data collection\n",
    "        2. Specific analysis requirements\n",
    "        3. Risk assessment focus areas\n",
    "        4. Success criteria for each task\n",
    "\n",
    "        Format your response as a structured JSON plan.\n",
    "        \"\"\")\n",
    "    \n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        self.logger.info(f\"Planning research for {query.ticker}\")\n",
    "        \n",
    "        prompt = self.planning_prompt.format(\n",
    "            ticker=query.ticker,\n",
    "            query_type=query.query_type,\n",
    "            time_horizon=query.time_horizon,\n",
    "            specific_questions=\", \".join(query.specific_questions),\n",
    "            risk_tolerance=query.risk_tolerance\n",
    "        )\n",
    "        \n",
    "        response = await self.llm.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "        \n",
    "        return AgentResponse(\n",
    "            agent_role=self.role,\n",
    "            content=response.content,\n",
    "            confidence=0.9,\n",
    "            sources=[\"internal_planning\"],\n",
    "            timestamp=datetime.now(),\n",
    "            metadata={\"query\": query.__dict__}\n",
    "        )\n",
    "\n",
    "class DataCollectionAgent(BaseAgent):\n",
    "    \"\"\"Agent responsible for gathering financial data from multiple sources\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.COLLECTOR)\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        \n",
    "    async def collect_financial_data(self, ticker: str) -> Dict[str, Any]:\n",
    "        \"\"\"Collect comprehensive financial data\"\"\"\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            # Get basic info\n",
    "            info = stock.info\n",
    "            \n",
    "            # Get financial statements\n",
    "            financials = stock.financials\n",
    "            balance_sheet = stock.balance_sheet\n",
    "            cash_flow = stock.cashflow\n",
    "            \n",
    "            # Get price history\n",
    "            price_data = stock.history(period=\"2y\")\n",
    "            financials_json = df_to_jsonable_records(financials.T)       # dates as index → records\n",
    "            balance_sheet_json = df_to_jsonable_records(balance_sheet.T)\n",
    "            cash_flow_json = df_to_jsonable_records(cash_flow.T)\n",
    "            price_history_json = df_to_jsonable_records(price_data.reset_index())\n",
    "    \n",
    "            news = stock.news[:10] if hasattr(stock, \"news\") else []\n",
    "    \n",
    "            return {\n",
    "                \"basic_info\": info,  # safe because we later dump with safe_json_serializer\n",
    "                \"financials\": financials_json,\n",
    "                \"balance_sheet\": balance_sheet_json,\n",
    "                \"cash_flow\": cash_flow_json,\n",
    "                \"price_history\": price_history_json,\n",
    "                \"news\": news\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error collecting data for {ticker}: {e}\")\n",
    "            return {}            \n",
    "    \n",
    "    async def collect_market_sentiment(self, ticker: str) -> Dict[str, Any]:\n",
    "        \"\"\"Collect market sentiment data\"\"\"\n",
    "        try:\n",
    "            # Placeholder for sentiment analysis\n",
    "            # In production, you'd integrate with news APIs, social media, etc.\n",
    "            sentiment_data = {\n",
    "                \"news_sentiment\": \"neutral\",\n",
    "                \"social_sentiment\": \"positive\",\n",
    "                \"analyst_sentiment\": \"bullish\",\n",
    "                \"confidence\": 0.7\n",
    "            }\n",
    "            return sentiment_data\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error collecting sentiment for {ticker}: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        self.logger.info(f\"Collecting data for {query.ticker}\")\n",
    "        \n",
    "        # Collect comprehensive data\n",
    "        financial_data = await self.collect_financial_data(query.ticker)\n",
    "        sentiment_data = await self.collect_market_sentiment(query.ticker)\n",
    "        \n",
    "        # Create documents for RAG\n",
    "        documents = []\n",
    "        \n",
    "        # Process financial data into documents\n",
    "        if financial_data.get(\"basic_info\"):\n",
    "            doc = Document(\n",
    "                page_content=f\"Company Info for {query.ticker}: {json.dumps(financial_data['basic_info'], default=str)}\",\n",
    "                metadata={\"source\": \"yfinance\", \"type\": \"company_info\", \"ticker\": query.ticker}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        \n",
    "        # Process news into documents\n",
    "        for news_item in financial_data.get(\"news\", []):\n",
    "            doc = Document(\n",
    "                page_content=f\"News: {news_item.get('title', '')} - {news_item.get('summary', '')}\",\n",
    "                metadata={\n",
    "                    \"source\": \"yfinance_news\",\n",
    "                    \"type\": \"news\",\n",
    "                    \"ticker\": query.ticker,\n",
    "                    \"publish_time\": news_item.get('providerPublishTime', 0)\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        \n",
    "        # Split documents\n",
    "        split_docs = self.text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Create vector store\n",
    "        if split_docs:\n",
    "            vectorstore = FAISS.from_documents(split_docs, self.embeddings)\n",
    "            # Save vectorstore for other agents\n",
    "            vectorstore.save_local(f\"vectorstore_{query.ticker}\")\n",
    "        \n",
    "        collected_data = {\n",
    "            \"financial_data\": financial_data,\n",
    "            \"sentiment_data\": sentiment_data,\n",
    "            \"document_count\": len(split_docs),\n",
    "            \"vectorstore_path\": f\"vectorstore_{query.ticker}\"\n",
    "        }\n",
    "        \n",
    "        return AgentResponse(\n",
    "            agent_role=self.role,\n",
    "            content=json.dumps(collected_data, default=safe_json_serializer),\n",
    "            confidence=0.8,\n",
    "            sources=[\"yfinance\", \"financial_apis\"],\n",
    "            timestamp=datetime.now(),\n",
    "            metadata={\"ticker\": query.ticker, \"documents_processed\": len(split_docs)}\n",
    "        )\n",
    "\n",
    "class AnalysisAgent(BaseAgent):\n",
    "    \"\"\"Agent responsible for analyzing collected data and identifying patterns\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.ANALYST)\n",
    "        self.analysis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an expert financial analyst. Analyze the provided financial data and generate \n",
    "        comprehensive insights for the investment research query.\n",
    "\n",
    "        Company: {ticker}\n",
    "        Query Type: {query_type}\n",
    "        Time Horizon: {time_horizon}\n",
    "\n",
    "        Financial Data Context:\n",
    "        {financial_context}\n",
    "\n",
    "        Recent News Context:\n",
    "        {news_context}\n",
    "\n",
    "        Provide a detailed analysis covering:\n",
    "        1. Financial health assessment\n",
    "        2. Growth prospects and trends\n",
    "        3. Competitive positioning\n",
    "        4. Key opportunities and threats\n",
    "        5. Investment recommendation with reasoning\n",
    "\n",
    "        Focus on actionable insights and quantitative metrics where available.\n",
    "        \"\"\")\n",
    "    \n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        self.logger.info(f\"Analyzing data for {query.ticker}\")\n",
    "        \n",
    "        # Load vectorstore created by data collection agent\n",
    "        try:\n",
    "            vectorstore = FAISS.load_local(\n",
    "                f\"vectorstore_{query.ticker}\", \n",
    "                self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            \n",
    "            # Retrieve relevant documents\n",
    "            retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "            \n",
    "            # Create context from retrieved documents\n",
    "            financial_docs = await retriever.ainvoke(\"financial statements earnings revenue\")\n",
    "            news_docs = await retriever.ainvoke(\"recent news developments\")\n",
    "            \n",
    "            financial_context = \"\\n\".join([doc.page_content for doc in financial_docs[:5]])\n",
    "            news_context = \"\\n\".join([doc.page_content for doc in news_docs[:3]])\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not load vectorstore: {e}\")\n",
    "            financial_context = \"Financial data unavailable\"\n",
    "            news_context = \"News data unavailable\"\n",
    "        \n",
    "        # Generate analysis\n",
    "        prompt = self.analysis_prompt.format(\n",
    "            ticker=query.ticker,\n",
    "            query_type=query.query_type,\n",
    "            time_horizon=query.time_horizon,\n",
    "            financial_context=financial_context,\n",
    "            news_context=news_context\n",
    "        )\n",
    "        \n",
    "        response = await self.llm.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "        \n",
    "        return AgentResponse(\n",
    "            agent_role=self.role,\n",
    "            content=response.content,\n",
    "            confidence=0.85,\n",
    "            sources=[\"financial_analysis\", \"vectorstore\"],\n",
    "            timestamp=datetime.now(),\n",
    "            metadata={\n",
    "                \"ticker\": query.ticker,\n",
    "                \"context_docs_used\": len(financial_docs) + len(news_docs) if 'financial_docs' in locals() else 0\n",
    "            }\n",
    "        )\n",
    "\n",
    "class RiskAssessmentAgent(BaseAgent):\n",
    "    \"\"\"Agent responsible for identifying and assessing investment risks\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.RISK_ASSESSOR)\n",
    "        self.risk_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an expert risk assessment analyst. Evaluate the investment risks for this research query.\n",
    "\n",
    "        Company: {ticker}\n",
    "        Risk Tolerance: {risk_tolerance}\n",
    "        Time Horizon: {time_horizon}\n",
    "\n",
    "        Analysis Context:\n",
    "        {analysis_context}\n",
    "\n",
    "        Financial Context:\n",
    "        {financial_context}\n",
    "\n",
    "        Provide a comprehensive risk assessment including:\n",
    "        1. Financial risks (liquidity, solvency, profitability)\n",
    "        2. Market risks (volatility, correlation, beta)\n",
    "        3. Operational risks (management, competition, regulation)\n",
    "        4. Macro-economic risks (interest rates, inflation, sector risks)\n",
    "        5. Risk mitigation strategies\n",
    "        6. Risk-adjusted recommendation\n",
    "\n",
    "        Rate each risk category from 1-10 and provide specific risk factors.\n",
    "        \"\"\")\n",
    "    \n",
    "    async def calculate_financial_metrics(self, ticker: str) -> Dict[str, float]:\n",
    "        \"\"\"Calculate key financial risk metrics\"\"\"\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info\n",
    "            \n",
    "            metrics = {\n",
    "                \"beta\": info.get(\"beta\", 1.0),\n",
    "                \"debt_to_equity\": info.get(\"debtToEquity\", 0.0) / 100 if info.get(\"debtToEquity\") else 0.0,\n",
    "                \"current_ratio\": info.get(\"currentRatio\", 1.0),\n",
    "                \"profit_margin\": info.get(\"profitMargins\", 0.0),\n",
    "                \"roa\": info.get(\"returnOnAssets\", 0.0),\n",
    "                \"roe\": info.get(\"returnOnEquity\", 0.0),\n",
    "                \"pe_ratio\": info.get(\"trailingPE\", 0.0),\n",
    "            }\n",
    "            \n",
    "            # Calculate volatility from price history\n",
    "            price_data = stock.history(period=\"1y\")\n",
    "            if not price_data.empty:\n",
    "                returns = price_data['Close'].pct_change().dropna()\n",
    "                metrics[\"volatility\"] = returns.std() * np.sqrt(252)  # Annualized\n",
    "                metrics[\"max_drawdown\"] = (price_data['Close'] / price_data['Close'].cummax() - 1).min()\n",
    "            \n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating metrics for {ticker}: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        self.logger.info(f\"Assessing risks for {query.ticker}\")\n",
    "        \n",
    "        # Get previous analysis context\n",
    "        analysis_context = context.get(\"analysis_content\", \"No previous analysis available\") if context else \"No context available\"\n",
    "        \n",
    "        # Calculate risk metrics\n",
    "        risk_metrics = await self.calculate_financial_metrics(query.ticker)\n",
    "        \n",
    "        # Load relevant financial context\n",
    "        try:\n",
    "            vectorstore = FAISS.load_local(\n",
    "                f\"vectorstore_{query.ticker}\", \n",
    "                self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "            risk_docs = await retriever.ainvoke(\"risk debt financial health liquidity\")\n",
    "            financial_context = \"\\n\".join([doc.page_content for doc in risk_docs])\n",
    "        except:\n",
    "            financial_context = f\"Risk Metrics: {json.dumps(risk_metrics, default=safe_json_serializer)}\"\n",
    "        \n",
    "        # Generate risk assessment\n",
    "        prompt = self.risk_prompt.format(\n",
    "            ticker=query.ticker,\n",
    "            risk_tolerance=query.risk_tolerance,\n",
    "            time_horizon=query.time_horizon,\n",
    "            analysis_context=analysis_context,\n",
    "            financial_context=financial_context\n",
    "        )\n",
    "        \n",
    "        response = await self.llm.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "        \n",
    "        return AgentResponse(\n",
    "            agent_role=self.role,\n",
    "            content=response.content,\n",
    "            confidence=0.8,\n",
    "            sources=[\"risk_analysis\", \"financial_metrics\"],\n",
    "            timestamp=datetime.now(),\n",
    "            metadata={\n",
    "                \"ticker\": query.ticker,\n",
    "                \"risk_metrics\": risk_metrics\n",
    "            }\n",
    "        )\n",
    "\n",
    "class InvestmentResearchOrchestrator:\n",
    "    \"\"\"Main orchestrator that coordinates all agents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.planning_agent = PlanningAgent()\n",
    "        self.collection_agent = DataCollectionAgent()\n",
    "        self.analysis_agent = AnalysisAgent()\n",
    "        self.risk_agent = RiskAssessmentAgent()\n",
    "        self.logger = logging.getLogger(\"orchestrator\")\n",
    "        \n",
    "    async def conduct_research(self, query: ResearchQuery) -> Dict[str, AgentResponse]:\n",
    "        \"\"\"Conduct comprehensive investment research using all agents\"\"\"\n",
    "        \n",
    "        self.logger.info(f\"Starting research for {query.ticker}\")\n",
    "        results = {}\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Planning\n",
    "            self.logger.info(\"Step 1: Planning research approach\")\n",
    "            results[\"planning\"] = await self.planning_agent.process(query)\n",
    "            \n",
    "            # Step 2: Data Collection\n",
    "            self.logger.info(\"Step 2: Collecting financial data\")\n",
    "            results[\"collection\"] = await self.collection_agent.process(query)\n",
    "            \n",
    "            # Step 3: Analysis\n",
    "            self.logger.info(\"Step 3: Analyzing collected data\")\n",
    "            results[\"analysis\"] = await self.analysis_agent.process(query)\n",
    "            \n",
    "            # Step 4: Risk Assessment\n",
    "            self.logger.info(\"Step 4: Assessing investment risks\")\n",
    "            context = {\"analysis_content\": results[\"analysis\"].content}\n",
    "            results[\"risk\"] = await self.risk_agent.process(query, context)\n",
    "            \n",
    "            self.logger.info(f\"Research completed for {query.ticker}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during research: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_research_report(self, query: ResearchQuery, results: Dict[str, AgentResponse]) -> str:\n",
    "        \"\"\"Generate a comprehensive research report\"\"\"\n",
    "        \n",
    "        report = f\"\"\"\n",
    "# Investment Research Report: {query.ticker}\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Executive Summary\n",
    "Query Type: {query.query_type.title()}\n",
    "Time Horizon: {query.time_horizon.title()}\n",
    "Risk Tolerance: {query.risk_tolerance.title()}\n",
    "\n",
    "## Research Plan\n",
    "{results.get('planning', {}).content if results.get('planning') else 'Planning unavailable'}\n",
    "\n",
    "## Data Collection Summary\n",
    "{f\"Documents processed: {results['collection'].metadata.get('documents_processed', 'N/A')}\" if results.get('collection') else 'Collection data unavailable'}\n",
    "\n",
    "## Financial Analysis\n",
    "{results.get('analysis', {}).content if results.get('analysis') else 'Analysis unavailable'}\n",
    "\n",
    "## Risk Assessment\n",
    "{results.get('risk', {}).content if results.get('risk') else 'Risk assessment unavailable'}\n",
    "\n",
    "## Agent Confidence Scores\n",
    "- Planning: {results.get('planning', {}).confidence if results.get('planning') else 'N/A'}\n",
    "- Collection: {results.get('collection', {}).confidence if results.get('collection') else 'N/A'}\n",
    "- Analysis: {results.get('analysis', {}).confidence if results.get('analysis') else 'N/A'}\n",
    "- Risk Assessment: {results.get('risk', {}).confidence if results.get('risk') else 'N/A'}\n",
    "\n",
    "---\n",
    "*This report was generated by an AI-powered investment research assistant. \n",
    "Please conduct additional due diligence before making investment decisions.*\n",
    "        \"\"\"\n",
    "        \n",
    "        return report.strip()\n",
    "\n",
    "# Jupyter-compatible execution functions\n",
    "async def run_research_example(ticker=\"AAPL\"):\n",
    "    \"\"\"Example usage of the Investment Research Assistant - Jupyter compatible\"\"\"\n",
    "    \n",
    "    # Verify API key is set\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"❌ OpenAI API key not found!\")\n",
    "        print(\"Please run: setup_api_key() first\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"🚀 Starting Investment Research for {ticker}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create research query\n",
    "    query = ResearchQuery(\n",
    "        ticker=ticker,\n",
    "        query_type=\"comprehensive\",\n",
    "        time_horizon=\"medium\",\n",
    "        specific_questions=[\n",
    "            \"What are the growth prospects for the next 2 years?\",\n",
    "            \"How does the company compare to competitors?\",\n",
    "            \"What are the main risk factors?\"\n",
    "        ],\n",
    "        risk_tolerance=\"moderate\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Initialize orchestrator (this will now check for API key)\n",
    "        orchestrator = InvestmentResearchOrchestrator()\n",
    "        \n",
    "        # Conduct research\n",
    "        results = await orchestrator.conduct_research(query)\n",
    "        \n",
    "        # Generate report\n",
    "        report = orchestrator.generate_research_report(query, results)\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"INVESTMENT RESEARCH REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        print(report)\n",
    "        \n",
    "        # Save results\n",
    "        filename = f\"research_report_{query.ticker}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"\\n📄 Report saved as: {filename}\")\n",
    "        return results, report\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Configuration error: {e}\")\n",
    "        print(\"Please run: setup_api_key() first\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during research: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "# API Key Management Functions\n",
    "def setup_api_key(api_key: str = None):\n",
    "    \"\"\"Set up OpenAI API key from various sources\"\"\"\n",
    "    \n",
    "    # Method 1: Direct parameter\n",
    "    if api_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        print(\"✅ OpenAI API key configured from parameter!\")\n",
    "        return True\n",
    "    \n",
    "    # Method 2: Check if already in environment\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"✅ OpenAI API key found in environment variables!\")\n",
    "        return True\n",
    "    \n",
    "    # Method 3: Try to load from config.py\n",
    "    try:\n",
    "        from config import OPENAI_API_KEY\n",
    "        os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "        print(\"✅ OpenAI API key loaded from config.py!\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"❌ config.py not found or OPENAI_API_KEY not defined in config.py\")\n",
    "        pass\n",
    "    \n",
    "    # Method 4: Try to load from .env file\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        if os.getenv(\"OPENAI_API_KEY\"):\n",
    "            print(\"✅ OpenAI API key loaded from .env file!\")\n",
    "            return True\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # If no key found\n",
    "    print(\"❌ No OpenAI API key found!\")\n",
    "    print(\"Options:\")\n",
    "    print(\"1. setup_api_key('your-key-here')\")\n",
    "    print(\"2. Create config.py with: OPENAI_API_KEY = 'your-key'\")\n",
    "    print(\"3. Create .env file with OPENAI_API_KEY=your-key\")\n",
    "    print(\"4. Set environment variable: export OPENAI_API_KEY='your-key'\")\n",
    "    return False\n",
    "\n",
    "def secure_input_api_key():\n",
    "    \"\"\"Securely input API key without showing it\"\"\"\n",
    "    import getpass\n",
    "    api_key = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "    return setup_api_key(api_key)\n",
    "\n",
    "# Interactive demo function\n",
    "def create_research_query(ticker: str, \n",
    "                         query_type: str = \"comprehensive\",\n",
    "                         time_horizon: str = \"medium\", \n",
    "                         risk_tolerance: str = \"moderate\",\n",
    "                         questions: List[str] = None) -> ResearchQuery:\n",
    "    \"\"\"Create a custom research query\"\"\"\n",
    "    \n",
    "    if questions is None:\n",
    "        questions = [\n",
    "            \"What is the overall investment outlook?\",\n",
    "            \"What are the key growth drivers?\",\n",
    "            \"What are the main risks to consider?\"\n",
    "        ]\n",
    "    \n",
    "    return ResearchQuery(\n",
    "        ticker=ticker.upper(),\n",
    "        query_type=query_type,\n",
    "        time_horizon=time_horizon,\n",
    "        specific_questions=questions,\n",
    "        risk_tolerance=risk_tolerance\n",
    "    )\n",
    "\n",
    "# For Jupyter Notebook execution:\n",
    "print(\"📊 Investment Research Assistant Loaded!\")\n",
    "print(\"\\n🔧 Setup Instructions:\")\n",
    "print(\"1. Set your API key: setup_api_key('your-openai-api-key-here')\")\n",
    "print(\"2. Run research: await run_research_example('AAPL')\")\n",
    "print(\"3. Or create custom query: query = create_research_query('MSFT', 'fundamental')\")\n",
    "print(\"\\n💡 Available functions:\")\n",
    "print(\"- setup_api_key(api_key)\")\n",
    "print(\"- run_research_example(ticker)\")\n",
    "print(\"- create_research_query(ticker, query_type, time_horizon, risk_tolerance, questions)\")\n",
    "\n",
    "# Example for direct execution in Jupyter:\n",
    "\"\"\"\n",
    "# Run this in separate Jupyter cells:\n",
    "\n",
    "# Cell 1: Setup\n",
    "setup_api_key(\"your-openai-api-key-here\")\n",
    "\n",
    "# Cell 2: Run research  \n",
    "results, report = await run_research_example(\"AAPL\")\n",
    "\n",
    "# Cell 3: Custom research\n",
    "custom_query = create_research_query(\n",
    "    ticker=\"MSFT\",\n",
    "    query_type=\"fundamental\", \n",
    "    questions=[\"How is the cloud business performing?\", \"What's the AI strategy?\"]\n",
    ")\n",
    "orchestrator = InvestmentResearchOrchestrator()\n",
    "custom_results = await orchestrator.conduct_research(custom_query)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aee437fa-c140-4bc0-8f8e-3f35d23c653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Investment Research Assistant Loaded!\n",
      "\n",
      "🔧 Setup Instructions:\n",
      "1. Set your API key: setup_api_key('your-openai-api-key-here')\n",
      "2. Run research: await run_research_example('AAPL')\n",
      "3. Or create custom query: query = create_research_query('MSFT', 'fundamental')\n",
      "\n",
      "💡 Available functions:\n",
      "- setup_api_key(api_key)\n",
      "- run_research_example(ticker)\n",
      "- create_research_query(ticker, query_type, time_horizon, risk_tolerance, questions)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Run this in separate Jupyter cells:\\n\\n# Cell 1: Setup\\nsetup_api_key(\"your-openai-api-key-here\")\\n\\n# Cell 2: Run research\\nresults, report = await run_research_example(\"AAPL\")\\n\\n# Cell 3: Custom research\\ncustom_query = create_research_query(\\n    ticker=\"MSFT\",\\n    query_type=\"fundamental\",\\n    questions=[\"How is the cloud business performing?\", \"What\\'s the AI strategy?\"]\\n)\\norchestrator = InvestmentResearchOrchestrator()\\ncustom_results = await orchestrator.conduct_research(custom_query)\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "AI-Powered Investment Research Assistant with Agentic RAG\n",
    "=======================================================\n",
    "\n",
    "This project demonstrates a multi-agent system for comprehensive investment analysis\n",
    "using RAG (Retrieval-Augmented Generation) architecture.\n",
    "\n",
    "Agents:\n",
    "1. Planning Agent - Breaks down complex research queries\n",
    "2. Data Collection Agent - Gathers information from multiple sources\n",
    "3. Analysis Agent - Synthesizes findings and identifies patterns\n",
    "4. Risk Assessment Agent - Flags potential concerns and risks\n",
    "\n",
    "Author: [Your Name]\n",
    "GitHub: [Your GitHub URL]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- LangChain imports (compat shim for newer/older versions) ----------------\n",
    "try:\n",
    "    # newer split packaging\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # type: ignore\n",
    "except Exception:\n",
    "    from langchain.chat_models import ChatOpenAI  # type: ignore\n",
    "    from langchain.embeddings import OpenAIEmbeddings  # type: ignore\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ============================== Helpers ======================================\n",
    "\n",
    "def safe_json_serializer(obj):\n",
    "    \"\"\"Safe JSON serializer for pandas objects and datetime (for VALUES only).\"\"\"\n",
    "    if isinstance(obj, pd.Timestamp):\n",
    "        return obj.isoformat()\n",
    "    elif isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):\n",
    "        return None\n",
    "    return str(obj)\n",
    "\n",
    "def df_to_jsonable_records(df: Optional[pd.DataFrame]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Convert a DataFrame to a JSON-safe list-of-records with ISO date strings.\"\"\"\n",
    "    if df is None or (hasattr(df, \"empty\") and df.empty):\n",
    "        return []\n",
    "    out = df.copy()\n",
    "\n",
    "    # If the index is date-like, keep it as a column\n",
    "    if isinstance(out.index, (pd.DatetimeIndex, pd.PeriodIndex)):\n",
    "        out = out.reset_index()\n",
    "\n",
    "    # Also if columns are periods/datetimes, cast to str\n",
    "    out.columns = [str(c) for c in out.columns]\n",
    "\n",
    "    # Convert any datetime-like columns to ISO strings\n",
    "    for c in out.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(out[c]):\n",
    "            out[c] = out[c].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Replace NaN with None so JSON is clean\n",
    "    out = out.where(pd.notnull(out), None)\n",
    "    return out.to_dict(orient=\"records\")\n",
    "\n",
    "def clamp(x: float, lo: float = 0.0, hi: float = 1.0) -> float:\n",
    "    return float(max(lo, min(hi, x)))\n",
    "\n",
    "def clamp_int(x: float, lo: int = 1, hi: int = 10) -> int:\n",
    "    return int(max(lo, min(hi, round(x))))\n",
    "\n",
    "# ============================ Core Types =====================================\n",
    "\n",
    "class AgentRole(Enum):\n",
    "    PLANNER = \"planning_agent\"\n",
    "    COLLECTOR = \"data_collection_agent\"\n",
    "    ANALYST = \"analysis_agent\"\n",
    "    RISK_ASSESSOR = \"risk_assessment_agent\"\n",
    "\n",
    "@dataclass\n",
    "class ResearchQuery:\n",
    "    \"\"\"Structure for investment research queries\"\"\"\n",
    "    ticker: str\n",
    "    query_type: str  # \"fundamental\", \"technical\", \"sentiment\", \"comprehensive\"\n",
    "    time_horizon: str  # \"short\", \"medium\", \"long\"\n",
    "    specific_questions: List[str]\n",
    "    risk_tolerance: str  # \"conservative\", \"moderate\", \"aggressive\"\n",
    "\n",
    "@dataclass\n",
    "class AgentResponse:\n",
    "    \"\"\"Structure for agent responses\"\"\"\n",
    "    agent_role: AgentRole\n",
    "    content: str\n",
    "    confidence: float\n",
    "    sources: List[str]\n",
    "    timestamp: datetime\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "# ================================ Agents =====================================\n",
    "\n",
    "class BaseAgent:\n",
    "    \"\"\"Base class for all agents\"\"\"\n",
    "\n",
    "    def __init__(self, role: AgentRole, llm_model: str = \"gpt-3.5-turbo\"):\n",
    "        self.role = role\n",
    "\n",
    "        # Ensure API key is set before initializing LLM\n",
    "        if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "            raise ValueError(\n",
    "                \"OpenAI API key not found! Please run setup_api_key() first or set OPENAI_API_KEY environment variable.\"\n",
    "            )\n",
    "\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=llm_model,\n",
    "            temperature=0.1,\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        self.logger = logging.getLogger(f\"{role.value}\")\n",
    "\n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        \"\"\"Abstract method to be implemented by each agent\"\"\"\n",
    "        raise NotImplementedError(\"Each agent must implement process method\")\n",
    "\n",
    "# ------------------------------ PlanningAgent --------------------------------\n",
    "\n",
    "class PlanningAgent(BaseAgent):\n",
    "    \"\"\"Agent responsible for breaking down research queries into actionable tasks\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.PLANNER)\n",
    "        self.planning_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an expert investment research planner. Break down this investment research query \n",
    "        into specific, actionable sub-tasks for other specialized agents.\n",
    "\n",
    "        Query Details:\n",
    "        - Ticker: {ticker}\n",
    "        - Query Type: {query_type}\n",
    "        - Time Horizon: {time_horizon}\n",
    "        - Specific Questions: {specific_questions}\n",
    "        - Risk Tolerance: {risk_tolerance}\n",
    "\n",
    "        Create a detailed research plan with:\n",
    "        1. Priority-ordered tasks for data collection\n",
    "        2. Specific analysis requirements\n",
    "        3. Risk assessment focus areas\n",
    "        4. Success criteria for each task\n",
    "\n",
    "        Format your response as a structured JSON plan.\n",
    "        \"\"\")\n",
    "\n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        self.logger.info(f\"Planning research for {query.ticker}\")\n",
    "\n",
    "        prompt = self.planning_prompt.format(\n",
    "            ticker=query.ticker,\n",
    "            query_type=query.query_type,\n",
    "            time_horizon=query.time_horizon,\n",
    "            specific_questions=\", \".join(query.specific_questions),\n",
    "            risk_tolerance=query.risk_tolerance\n",
    "        )\n",
    "\n",
    "        response = await self.llm.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "        # Planning is LLM-only; keep confidence high but bounded\n",
    "        confidence = 0.9\n",
    "\n",
    "        return AgentResponse(\n",
    "            agent_role=self.role,\n",
    "            content=response.content,\n",
    "            confidence=confidence,\n",
    "            sources=[\"internal_planning\"],\n",
    "            timestamp=datetime.now(),\n",
    "            metadata={\"query\": query.__dict__}\n",
    "        )\n",
    "\n",
    "# --------------------------- DataCollectionAgent -----------------------------\n",
    "\n",
    "class DataCollectionAgent(BaseAgent):\n",
    "    \"\"\"Agent responsible for gathering financial data from multiple sources\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.COLLECTOR)\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "\n",
    "    async def collect_financial_data(self, ticker: str) -> Dict[str, Any]:\n",
    "        \"\"\"Collect comprehensive financial data\"\"\"\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "\n",
    "            # Get basic info (yfinance sometimes fails for .info)\n",
    "            info = {}\n",
    "            try:\n",
    "                info = stock.info\n",
    "            except Exception:\n",
    "                info = getattr(stock, \"fast_info\", {}) or {}\n",
    "\n",
    "            # Financial statements\n",
    "            financials = stock.financials\n",
    "            balance_sheet = stock.balance_sheet\n",
    "            cash_flow = stock.cashflow\n",
    "\n",
    "            # Price history\n",
    "            price_data = stock.history(period=\"2y\")\n",
    "\n",
    "            # JSON-safe versions (avoid Timestamp keys)\n",
    "            financials_json = df_to_jsonable_records(financials.T)\n",
    "            balance_sheet_json = df_to_jsonable_records(balance_sheet.T)\n",
    "            cash_flow_json = df_to_jsonable_records(cash_flow.T)\n",
    "            price_history_json = df_to_jsonable_records(price_data.reset_index())\n",
    "\n",
    "            # News\n",
    "            news = stock.news[:10] if hasattr(stock, \"news\") and stock.news else []\n",
    "\n",
    "            return {\n",
    "                \"basic_info\": info,\n",
    "                \"financials\": financials_json,\n",
    "                \"balance_sheet\": balance_sheet_json,\n",
    "                \"cash_flow\": cash_flow_json,\n",
    "                \"price_history\": price_history_json,\n",
    "                \"news\": news\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error collecting data for {ticker}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    async def collect_market_sentiment(self, ticker: str) -> Dict[str, Any]:\n",
    "        \"\"\"Collect market sentiment data (placeholder)\"\"\"\n",
    "        try:\n",
    "            sentiment_data = {\n",
    "                \"news_sentiment\": \"neutral\",\n",
    "                \"social_sentiment\": \"positive\",\n",
    "                \"analyst_sentiment\": \"bullish\",\n",
    "                \"confidence\": 0.7\n",
    "            }\n",
    "            return sentiment_data\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error collecting sentiment for {ticker}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        self.logger.info(f\"Collecting data for {query.ticker}\")\n",
    "\n",
    "        # Collect comprehensive data\n",
    "        financial_data = await self.collect_financial_data(query.ticker)\n",
    "        sentiment_data = await self.collect_market_sentiment(query.ticker)\n",
    "\n",
    "        # Create documents for RAG\n",
    "        documents = []\n",
    "\n",
    "        # Process financial data into documents\n",
    "        if financial_data.get(\"basic_info\"):\n",
    "            doc = Document(\n",
    "                page_content=f\"Company Info for {query.ticker}: {json.dumps(financial_data['basic_info'], default=str)}\",\n",
    "                metadata={\"source\": \"yfinance\", \"type\": \"company_info\", \"ticker\": query.ticker}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "        # Process news into documents\n",
    "        for news_item in financial_data.get(\"news\", []):\n",
    "            doc = Document(\n",
    "                page_content=f\"News: {news_item.get('title', '')} - {news_item.get('summary', '')}\",\n",
    "                metadata={\n",
    "                    \"source\": \"yfinance_news\",\n",
    "                    \"type\": \"news\",\n",
    "                    \"ticker\": query.ticker,\n",
    "                    \"publish_time\": news_item.get('providerPublishTime', 0)\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "        # Split documents\n",
    "        split_docs = self.text_splitter.split_documents(documents)\n",
    "\n",
    "        # Create vector store\n",
    "        vectorstore_path = f\"vectorstore_{query.ticker}\"\n",
    "        if split_docs:\n",
    "            vectorstore = FAISS.from_documents(split_docs, self.embeddings)\n",
    "            os.makedirs(vectorstore_path, exist_ok=True)\n",
    "            vectorstore.save_local(vectorstore_path)\n",
    "\n",
    "        collected_data = {\n",
    "            \"financial_data\": financial_data,\n",
    "            \"sentiment_data\": sentiment_data,\n",
    "            \"document_count\": len(split_docs),\n",
    "            \"vectorstore_path\": vectorstore_path\n",
    "        }\n",
    "\n",
    "        # -------- Dynamic confidence (data quality driven) --------\n",
    "        base = 0.4\n",
    "        if financial_data.get(\"basic_info\"):\n",
    "            base += 0.2\n",
    "        if financial_data.get(\"price_history\"):\n",
    "            has_prices = len(financial_data[\"price_history\"]) > 0\n",
    "            base += 0.1 if has_prices else 0.0\n",
    "        if financial_data.get(\"news\"):\n",
    "            base += 0.1\n",
    "        base += min(0.2, len(split_docs) / 40.0)  # more docs → higher confidence\n",
    "        confidence = round(clamp(base, 0.0, 0.95), 2)\n",
    "        # ----------------------------------------------------------\n",
    "\n",
    "        return AgentResponse(\n",
    "            agent_role=self.role,\n",
    "            content=json.dumps(collected_data, default=safe_json_serializer),\n",
    "            confidence=confidence,\n",
    "            sources=[\"yfinance\", \"financial_apis\"],\n",
    "            timestamp=datetime.now(),\n",
    "            metadata={\"ticker\": query.ticker, \"documents_processed\": len(split_docs)}\n",
    "        )\n",
    "\n",
    "# ------------------------------ AnalysisAgent --------------------------------\n",
    "\n",
    "class AnalysisAgent(BaseAgent):\n",
    "    \"\"\"Agent responsible for analyzing collected data and identifying patterns\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.ANALYST)\n",
    "        self.analysis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an expert financial analyst. Analyze the provided financial data and generate \n",
    "        comprehensive insights for the investment research query.\n",
    "\n",
    "        Company: {ticker}\n",
    "        Query Type: {query_type}\n",
    "        Time Horizon: {time_horizon}\n",
    "\n",
    "        Financial Data Context:\n",
    "        {financial_context}\n",
    "\n",
    "        Recent News Context:\n",
    "        {news_context}\n",
    "\n",
    "        Provide a detailed analysis covering:\n",
    "        1. Financial health assessment\n",
    "        2. Growth prospects and trends\n",
    "        3. Competitive positioning\n",
    "        4. Key opportunities and threats\n",
    "        5. Investment recommendation with reasoning\n",
    "\n",
    "        Focus on actionable insights and quantitative metrics where available.\n",
    "        \"\"\")\n",
    "\n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        self.logger.info(f\"Analyzing data for {query.ticker}\")\n",
    "\n",
    "        # Load vectorstore created by data collection agent\n",
    "        n_fin = 0\n",
    "        n_news = 0\n",
    "        try:\n",
    "            vectorstore = FAISS.load_local(\n",
    "                f\"vectorstore_{query.ticker}\",\n",
    "                self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "\n",
    "            # Retrieve relevant documents\n",
    "            retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "            # Create context from retrieved documents\n",
    "            financial_docs = await retriever.ainvoke(\"financial statements earnings revenue\")\n",
    "            news_docs = await retriever.ainvoke(\"recent news developments\")\n",
    "\n",
    "            n_fin = len(financial_docs)\n",
    "            n_news = len(news_docs)\n",
    "\n",
    "            financial_context = \"\\n\".join([doc.page_content for doc in financial_docs[:5]])\n",
    "            news_context = \"\\n\".join([doc.page_content for doc in news_docs[:3]])\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not load vectorstore: {e}\")\n",
    "            financial_context = \"Financial data unavailable\"\n",
    "            news_context = \"News data unavailable\"\n",
    "\n",
    "        # Generate analysis\n",
    "        prompt = self.analysis_prompt.format(\n",
    "            ticker=query.ticker,\n",
    "            query_type=query.query_type,\n",
    "            time_horizon=query.time_horizon,\n",
    "            financial_context=financial_context,\n",
    "            news_context=news_context\n",
    "        )\n",
    "\n",
    "        response = await self.llm.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "        # -------- Dynamic confidence (retrieval coverage driven) ---------------\n",
    "        conf = 0.4\n",
    "        conf += min(0.35, n_fin / 20.0)   # up to +0.35 from financial docs\n",
    "        conf += min(0.2, n_news / 10.0)   # up to +0.20 from news docs\n",
    "        if \"unavailable\" not in financial_context:\n",
    "            conf += 0.05\n",
    "        confidence = round(clamp(conf, 0.0, 0.95), 2)\n",
    "        # ----------------------------------------------------------------------\n",
    "\n",
    "        return AgentResponse(\n",
    "            agent_role=self.role,\n",
    "            content=response.content,\n",
    "            confidence=confidence,\n",
    "            sources=[\"financial_analysis\", \"vectorstore\"],\n",
    "            timestamp=datetime.now(),\n",
    "            metadata={\n",
    "                \"ticker\": query.ticker,\n",
    "                \"context_docs_used\": (n_fin + n_news)\n",
    "            }\n",
    "        )\n",
    "\n",
    "# --------------------------- RiskAssessmentAgent -----------------------------\n",
    "\n",
    "class RiskAssessmentAgent(BaseAgent):\n",
    "    \"\"\"Agent responsible for identifying and assessing investment risks\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(AgentRole.RISK_ASSESSOR)\n",
    "        self.risk_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an expert risk assessment analyst. Below are pre-computed, heuristic risk scores (1–10)\n",
    "        and underlying metrics. Provide concise commentary and mitigation strategies for each category.\n",
    "        \n",
    "        Company: {ticker}\n",
    "        Risk Tolerance: {risk_tolerance}\n",
    "        Time Horizon: {time_horizon}\n",
    "\n",
    "        Heuristic Risk Scores (1–10):\n",
    "        {risk_scores_json}\n",
    "\n",
    "        Metrics:\n",
    "        {metrics_json}\n",
    "\n",
    "        Provide:\n",
    "        - Short rationale per category (financial, market, operational, macro)\n",
    "        - 3–5 concrete mitigation strategies\n",
    "        - A risk-adjusted recommendation\n",
    "        \"\"\")\n",
    "\n",
    "    # ---------- Heuristic scoring helpers ------------------------------------\n",
    "    def _score_financial(self, m: Dict[str, float]) -> int:\n",
    "        dte = m.get(\"debt_to_equity\")\n",
    "        curr = m.get(\"current_ratio\")\n",
    "        pm = m.get(\"profit_margin\")\n",
    "\n",
    "        # D/E → higher = riskier\n",
    "        if dte is None:\n",
    "            dte_score = 5\n",
    "        elif dte >= 2.5:\n",
    "            dte_score = 10\n",
    "        elif dte >= 2.0:\n",
    "            dte_score = 8\n",
    "        elif dte >= 1.5:\n",
    "            dte_score = 7\n",
    "        elif dte >= 1.0:\n",
    "            dte_score = 6\n",
    "        else:\n",
    "            dte_score = 4\n",
    "\n",
    "        # Current ratio → lower = riskier\n",
    "        if curr is None:\n",
    "            curr_score = 5\n",
    "        elif curr < 1.0:\n",
    "            curr_score = 9\n",
    "        elif curr < 1.5:\n",
    "            curr_score = 7\n",
    "        elif curr < 2.0:\n",
    "            curr_score = 5\n",
    "        else:\n",
    "            curr_score = 3\n",
    "\n",
    "        # Profit margin → lower/negative = riskier\n",
    "        if pm is None:\n",
    "            pm_score = 5\n",
    "        elif pm < 0:\n",
    "            pm_score = 9\n",
    "        elif pm < 0.05:\n",
    "            pm_score = 7\n",
    "        elif pm < 0.15:\n",
    "            pm_score = 5\n",
    "        else:\n",
    "            pm_score = 3\n",
    "\n",
    "        # Weighted average\n",
    "        score = 0.4 * dte_score + 0.35 * curr_score + 0.25 * pm_score\n",
    "        return clamp_int(score, 1, 10)\n",
    "\n",
    "    def _score_market(self, m: Dict[str, float]) -> int:\n",
    "        beta = m.get(\"beta\")\n",
    "        vol = m.get(\"volatility\")\n",
    "\n",
    "        # Volatility annualized: ~0.15–0.6 typical; scale to 1–10\n",
    "        if vol is None:\n",
    "            vol_score = 5\n",
    "        else:\n",
    "            vol_score = clamp_int(vol * 20.0, 1, 10)  # 0.5 vol → score 10\n",
    "\n",
    "        # Beta scaling\n",
    "        if beta is None:\n",
    "            beta_score = 5\n",
    "        elif beta >= 2.0:\n",
    "            beta_score = 9\n",
    "        elif beta >= 1.5:\n",
    "            beta_score = 8\n",
    "        elif beta >= 1.2:\n",
    "            beta_score = 7\n",
    "        elif beta >= 1.0:\n",
    "            beta_score = 6\n",
    "        elif beta >= 0.8:\n",
    "            beta_score = 5\n",
    "        elif beta >= 0.5:\n",
    "            beta_score = 4\n",
    "        else:\n",
    "            beta_score = 3\n",
    "\n",
    "        score = 0.6 * vol_score + 0.4 * beta_score\n",
    "        return clamp_int(score, 1, 10)\n",
    "\n",
    "    def _score_operational(self, m: Dict[str, float]) -> int:\n",
    "        # Proxy with profitability & asset returns (lack of direct ops inputs)\n",
    "        roa = m.get(\"roa\")\n",
    "        roe = m.get(\"roe\")\n",
    "        pm = m.get(\"profit_margin\")\n",
    "        curr = m.get(\"current_ratio\")\n",
    "\n",
    "        score = 5  # base\n",
    "        if pm is not None and pm < 0:\n",
    "            score += 2\n",
    "        if roa is not None and roa < 0:\n",
    "            score += 2\n",
    "        if roe is not None and roe < 0:\n",
    "            score += 2\n",
    "        if curr is not None and curr < 1.0:\n",
    "            score += 1\n",
    "\n",
    "        return clamp_int(score, 1, 10)\n",
    "\n",
    "    def _score_macro(self, m: Dict[str, float]) -> int:\n",
    "        # Without macro inputs, proxy with beta (sensitivity) around neutral 5\n",
    "        beta = m.get(\"beta\")\n",
    "        score = 5\n",
    "        if beta is not None:\n",
    "            if beta >= 1.5:\n",
    "                score += 2\n",
    "            elif beta <= 0.8:\n",
    "                score -= 1\n",
    "        return clamp_int(score, 1, 10)\n",
    "\n",
    "    async def calculate_financial_metrics(self, ticker: str) -> Dict[str, float]:\n",
    "        \"\"\"Calculate key financial risk metrics\"\"\"\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = {}\n",
    "            try:\n",
    "                info = stock.info\n",
    "            except Exception:\n",
    "                info = getattr(stock, \"fast_info\", {}) or {}\n",
    "\n",
    "            metrics = {\n",
    "                \"beta\": info.get(\"beta\", None),\n",
    "                \"debt_to_equity\": (info.get(\"debtToEquity\") / 100.0) if info.get(\"debtToEquity\") else None,\n",
    "                \"current_ratio\": info.get(\"currentRatio\", None),\n",
    "                \"profit_margin\": info.get(\"profitMargins\", None),\n",
    "                \"roa\": info.get(\"returnOnAssets\", None),\n",
    "                \"roe\": info.get(\"returnOnEquity\", None),\n",
    "                \"pe_ratio\": info.get(\"trailingPE\", None),\n",
    "            }\n",
    "\n",
    "            # Calculate volatility & max drawdown from price history\n",
    "            price_data = stock.history(period=\"1y\")\n",
    "            if not price_data.empty:\n",
    "                returns = price_data['Close'].pct_change().dropna()\n",
    "                metrics[\"volatility\"] = float(returns.std() * np.sqrt(252))  # Annualized\n",
    "                metrics[\"max_drawdown\"] = float((price_data['Close'] / price_data['Close'].cummax() - 1).min())\n",
    "\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating metrics for {ticker}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    async def process(self, query: ResearchQuery, context: Dict[str, Any] = None) -> AgentResponse:\n",
    "        self.logger.info(f\"Assessing risks for {query.ticker}\")\n",
    "\n",
    "        # Previous analysis context (optional)\n",
    "        analysis_context = context.get(\"analysis_content\", \"No previous analysis available\") if context else \"No context available\"\n",
    "\n",
    "        # Calculate risk metrics (data-driven)\n",
    "        risk_metrics = await self.calculate_financial_metrics(query.ticker)\n",
    "\n",
    "        # Compute heuristic scores (1–10)\n",
    "        financial_risk = self._score_financial(risk_metrics)\n",
    "        market_risk = self._score_market(risk_metrics)\n",
    "        operational_risk = self._score_operational(risk_metrics)\n",
    "        macro_risk = self._score_macro(risk_metrics)\n",
    "\n",
    "        # Simple overall risk (weighted)\n",
    "        overall_risk = clamp_int(0.35 * financial_risk + 0.35 * market_risk + 0.2 * operational_risk + 0.1 * macro_risk)\n",
    "\n",
    "        risk_scores = {\n",
    "            \"financial\": financial_risk,\n",
    "            \"market\": market_risk,\n",
    "            \"operational\": operational_risk,\n",
    "            \"macro\": macro_risk,\n",
    "            \"overall\": overall_risk\n",
    "        }\n",
    "\n",
    "        # Load additional context from vectorstore (optional)\n",
    "        try:\n",
    "            vectorstore = FAISS.load_local(\n",
    "                f\"vectorstore_{query.ticker}\",\n",
    "                self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "            risk_docs = await retriever.ainvoke(\"risk debt financial health liquidity\")\n",
    "            financial_context = \"\\n\".join([doc.page_content for doc in risk_docs])\n",
    "        except Exception:\n",
    "            financial_context = f\"Risk Metrics: {json.dumps(risk_metrics, default=safe_json_serializer)}\"\n",
    "\n",
    "        # Build LLM prompt with pre-computed scores for commentary\n",
    "        prompt = self.risk_prompt.format(\n",
    "            ticker=query.ticker,\n",
    "            risk_tolerance=query.risk_tolerance,\n",
    "            time_horizon=query.time_horizon,\n",
    "            risk_scores_json=json.dumps(risk_scores, indent=2),\n",
    "            metrics_json=json.dumps(risk_metrics, indent=2, default=safe_json_serializer)\n",
    "        )\n",
    "\n",
    "        llm_response = await self.llm.ainvoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "        # Compose final content: show computed scores + LLM commentary\n",
    "        content = (\n",
    "            \"Calculated Risk Scores (Heuristic):\\n\"\n",
    "            + json.dumps(risk_scores, indent=2) + \"\\n\\n\"\n",
    "            + \"Metrics:\\n\"\n",
    "            + json.dumps(risk_metrics, indent=2, default=safe_json_serializer) + \"\\n\\n\"\n",
    "            + \"Expert Commentary & Mitigations:\\n\"\n",
    "            + llm_response.content\n",
    "        )\n",
    "\n",
    "        # -------- Dynamic confidence (metric coverage driven) ------------------\n",
    "        keys_considered = [\"beta\", \"debt_to_equity\", \"current_ratio\", \"profit_margin\", \"volatility\", \"max_drawdown\"]\n",
    "        coverage = sum(1 for k in keys_considered if risk_metrics.get(k) is not None)\n",
    "        confidence = round(clamp(0.5 + 0.08 * coverage, 0.0, 0.95), 2)  # 0.5 base + up to +0.48\n",
    "        # ----------------------------------------------------------------------\n",
    "\n",
    "        return AgentResponse(\n",
    "            agent_role=self.role,\n",
    "            content=content,\n",
    "            confidence=confidence,\n",
    "            sources=[\"risk_analysis\", \"financial_metrics\", \"vectorstore\"],\n",
    "            timestamp=datetime.now(),\n",
    "            metadata={\n",
    "                \"ticker\": query.ticker,\n",
    "                \"risk_metrics\": risk_metrics,\n",
    "                \"risk_scores\": risk_scores\n",
    "            }\n",
    "        )\n",
    "\n",
    "# ============================== Orchestrator =================================\n",
    "\n",
    "class InvestmentResearchOrchestrator:\n",
    "    \"\"\"Main orchestrator that coordinates all agents\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.planning_agent = PlanningAgent()\n",
    "        self.collection_agent = DataCollectionAgent()\n",
    "        self.analysis_agent = AnalysisAgent()\n",
    "        self.risk_agent = RiskAssessmentAgent()\n",
    "        self.logger = logging.getLogger(\"orchestrator\")\n",
    "\n",
    "    async def conduct_research(self, query: ResearchQuery) -> Dict[str, AgentResponse]:\n",
    "        \"\"\"Conduct comprehensive investment research using all agents\"\"\"\n",
    "\n",
    "        self.logger.info(f\"Starting research for {query.ticker}\")\n",
    "        results: Dict[str, AgentResponse] = {}\n",
    "\n",
    "        try:\n",
    "            # Step 1: Planning\n",
    "            self.logger.info(\"Step 1: Planning research approach\")\n",
    "            results[\"planning\"] = await self.planning_agent.process(query)\n",
    "\n",
    "            # Step 2: Data Collection\n",
    "            self.logger.info(\"Step 2: Collecting financial data\")\n",
    "            results[\"collection\"] = await self.collection_agent.process(query)\n",
    "\n",
    "            # Step 3: Analysis\n",
    "            self.logger.info(\"Step 3: Analyzing collected data\")\n",
    "            results[\"analysis\"] = await self.analysis_agent.process(query)\n",
    "\n",
    "            # Step 4: Risk Assessment\n",
    "            self.logger.info(\"Step 4: Assessing investment risks\")\n",
    "            context = {\"analysis_content\": results[\"analysis\"].content}\n",
    "            results[\"risk\"] = await self.risk_agent.process(query, context)\n",
    "\n",
    "            self.logger.info(f\"Research completed for {query.ticker}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during research: {e}\")\n",
    "            raise\n",
    "\n",
    "        return results\n",
    "\n",
    "    def generate_research_report(self, query: ResearchQuery, results: Dict[str, AgentResponse]) -> str:\n",
    "        \"\"\"Generate a comprehensive research report\"\"\"\n",
    "\n",
    "        # Try to surface risk scores cleanly if available\n",
    "        risk_scores_str = \"Risk assessment unavailable\"\n",
    "        if results.get(\"risk\") and results[\"risk\"].metadata.get(\"risk_scores\"):\n",
    "            rs = results[\"risk\"].metadata[\"risk_scores\"]\n",
    "            risk_scores_str = (\n",
    "                f\"- Financial: {rs['financial']}/10\\n\"\n",
    "                f\"- Market: {rs['market']}/10\\n\"\n",
    "                f\"- Operational: {rs['operational']}/10\\n\"\n",
    "                f\"- Macro: {rs['macro']}/10\\n\"\n",
    "                f\"- Overall: {rs['overall']}/10\"\n",
    "            )\n",
    "\n",
    "        report = f\"\"\"\n",
    "# Investment Research Report: {query.ticker}\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Executive Summary\n",
    "Query Type: {query.query_type.title()}\n",
    "Time Horizon: {query.time_horizon.title()}\n",
    "Risk Tolerance: {query.risk_tolerance.title()}\n",
    "\n",
    "## Research Plan\n",
    "{results.get('planning', {}).content if results.get('planning') else 'Planning unavailable'}\n",
    "\n",
    "## Data Collection Summary\n",
    "{f\"Documents processed: {results['collection'].metadata.get('documents_processed', 'N/A')}\" if results.get('collection') else 'Collection data unavailable'}\n",
    "\n",
    "## Financial Analysis\n",
    "{results.get('analysis', {}).content if results.get('analysis') else 'Analysis unavailable'}\n",
    "\n",
    "## Risk Assessment (Calculated Scores)\n",
    "{risk_scores_str}\n",
    "\n",
    "### Risk Commentary\n",
    "{results.get('risk', {}).content if results.get('risk') else 'Risk assessment unavailable'}\n",
    "\n",
    "## Agent Confidence Scores\n",
    "- Planning: {results.get('planning', {}).confidence if results.get('planning') else 'N/A'}\n",
    "- Collection: {results.get('collection', {}).confidence if results.get('collection') else 'N/A'}\n",
    "- Analysis: {results.get('analysis', {}).confidence if results.get('analysis') else 'N/A'}\n",
    "- Risk Assessment: {results.get('risk', {}).confidence if results.get('risk') else 'N/A'}\n",
    "\n",
    "---\n",
    "*This report was generated by an AI-powered investment research assistant. \n",
    "Please conduct additional due diligence before making investment decisions.*\n",
    "        \"\"\"\n",
    "\n",
    "        return report.strip()\n",
    "\n",
    "# ======================== Jupyter-compatible functions =======================\n",
    "\n",
    "async def run_research_example(ticker=\"AAPL\"):\n",
    "    \"\"\"Example usage of the Investment Research Assistant - Jupyter compatible\"\"\"\n",
    "\n",
    "    # Verify API key is set\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"❌ OpenAI API key not found!\")\n",
    "        print(\"Please run: setup_api_key() first\")\n",
    "        return None, None\n",
    "\n",
    "    print(f\"🚀 Starting Investment Research for {ticker}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Create research query\n",
    "    query = ResearchQuery(\n",
    "        ticker=ticker,\n",
    "        query_type=\"comprehensive\",\n",
    "        time_horizon=\"medium\",\n",
    "        specific_questions=[\n",
    "            \"What are the growth prospects for the next 2 years?\",\n",
    "            \"How does the company compare to competitors?\",\n",
    "            \"What are the main risk factors?\"\n",
    "        ],\n",
    "        risk_tolerance=\"moderate\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Initialize orchestrator (this will now check for API key)\n",
    "        orchestrator = InvestmentResearchOrchestrator()\n",
    "\n",
    "        # Conduct research\n",
    "        results = await orchestrator.conduct_research(query)\n",
    "\n",
    "        # Generate report\n",
    "        report = orchestrator.generate_research_report(query, results)\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"INVESTMENT RESEARCH REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        print(report)\n",
    "\n",
    "        # Save results\n",
    "        filename = f\"research_report_{query.ticker}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(report)\n",
    "\n",
    "        print(f\"\\n📄 Report saved as: {filename}\")\n",
    "        return results, report\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Configuration error: {e}\")\n",
    "        print(\"Please run: setup_api_key() first\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during research: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "# ========================= API Key Management ================================\n",
    "\n",
    "def setup_api_key(api_key: str = None):\n",
    "    \"\"\"Set up OpenAI API key from various sources\"\"\"\n",
    "\n",
    "    # Method 1: Direct parameter\n",
    "    if api_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        print(\"✅ OpenAI API key configured from parameter!\")\n",
    "        return True\n",
    "\n",
    "    # Method 2: Check if already in environment\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"✅ OpenAI API key found in environment variables!\")\n",
    "        return True\n",
    "\n",
    "    # Method 3: Try to load from config.py\n",
    "    try:\n",
    "        from config import OPENAI_API_KEY\n",
    "        os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "        print(\"✅ OpenAI API key loaded from config.py!\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"❌ config.py not found or OPENAI_API_KEY not defined in config.py\")\n",
    "        pass\n",
    "\n",
    "    # Method 4: Try to load from .env file\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        if os.getenv(\"OPENAI_API_KEY\"):\n",
    "            print(\"✅ OpenAI API key loaded from .env file!\")\n",
    "            return True\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    # If no key found\n",
    "    print(\"❌ No OpenAI API key found!\")\n",
    "    print(\"Options:\")\n",
    "    print(\"1. setup_api_key('your-key-here')\")\n",
    "    print(\"2. Create config.py with: OPENAI_API_KEY = 'your-key'\")\n",
    "    print(\"3. Create .env file with OPENAI_API_KEY=your-key\")\n",
    "    print(\"4. Set environment variable: export OPENAI_API_KEY='your-key'\")\n",
    "    return False\n",
    "\n",
    "def secure_input_api_key():\n",
    "    \"\"\"Securely input API key without showing it\"\"\"\n",
    "    import getpass\n",
    "    api_key = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "    return setup_api_key(api_key)\n",
    "\n",
    "# ============================== Convenience ==================================\n",
    "\n",
    "def create_research_query(ticker: str,\n",
    "                         query_type: str = \"comprehensive\",\n",
    "                         time_horizon: str = \"medium\",\n",
    "                         risk_tolerance: str = \"moderate\",\n",
    "                         questions: List[str] = None) -> ResearchQuery:\n",
    "    \"\"\"Create a custom research query\"\"\"\n",
    "\n",
    "    if questions is None:\n",
    "        questions = [\n",
    "            \"What is the overall investment outlook?\",\n",
    "            \"What are the key growth drivers?\",\n",
    "            \"What are the main risks to consider?\"\n",
    "        ]\n",
    "\n",
    "    return ResearchQuery(\n",
    "        ticker=ticker.upper(),\n",
    "        query_type=query_type,\n",
    "        time_horizon=time_horizon,\n",
    "        specific_questions=questions,\n",
    "        risk_tolerance=risk_tolerance\n",
    "    )\n",
    "\n",
    "# For Jupyter Notebook execution:\n",
    "print(\"📊 Investment Research Assistant Loaded!\")\n",
    "print(\"\\n🔧 Setup Instructions:\")\n",
    "print(\"1. Set your API key: setup_api_key('your-openai-api-key-here')\")\n",
    "print(\"2. Run research: await run_research_example('AAPL')\")\n",
    "print(\"3. Or create custom query: query = create_research_query('MSFT', 'fundamental')\")\n",
    "print(\"\\n💡 Available functions:\")\n",
    "print(\"- setup_api_key(api_key)\")\n",
    "print(\"- run_research_example(ticker)\")\n",
    "print(\"- create_research_query(ticker, query_type, time_horizon, risk_tolerance, questions)\")\n",
    "\n",
    "# Example for direct execution in Jupyter:\n",
    "\"\"\"\n",
    "# Run this in separate Jupyter cells:\n",
    "\n",
    "# Cell 1: Setup\n",
    "setup_api_key(\"your-openai-api-key-here\")\n",
    "\n",
    "# Cell 2: Run research\n",
    "results, report = await run_research_example(\"AAPL\")\n",
    "\n",
    "# Cell 3: Custom research\n",
    "custom_query = create_research_query(\n",
    "    ticker=\"MSFT\",\n",
    "    query_type=\"fundamental\",\n",
    "    questions=[\"How is the cloud business performing?\", \"What's the AI strategy?\"]\n",
    ")\n",
    "orchestrator = InvestmentResearchOrchestrator()\n",
    "custom_results = await orchestrator.conduct_research(custom_query)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff8a6926-e288-4b50-a98b-a1a4e27abe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API key found in environment variables!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should now work properly\n",
    "setup_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dcf1b8f4-4f98-4530-a5be-b9b6af32641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key set: True\n",
      "Key starts with: sk-proj-y0...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"API Key set: {bool(os.getenv('OPENAI_API_KEY'))}\")\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    key = os.getenv('OPENAI_API_KEY')\n",
    "    print(f\"Key starts with: {key[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b524bced-7438-470f-80e2-08db5617fc23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Investment Research for AAPL\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Starting research for AAPL\n",
      "INFO:orchestrator:Step 1: Planning research approach\n",
      "INFO:planning_agent:Planning research for AAPL\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestrator:Step 2: Collecting financial data\n",
      "INFO:data_collection_agent:Collecting data for AAPL\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestrator:Step 3: Analyzing collected data\n",
      "INFO:analysis_agent:Analyzing data for AAPL\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestrator:Step 4: Assessing investment risks\n",
      "INFO:risk_assessment_agent:Assessing risks for AAPL\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestrator:Research completed for AAPL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INVESTMENT RESEARCH REPORT\n",
      "================================================================================\n",
      "# Investment Research Report: AAPL\n",
      "Generated on: 2025-09-29 19:32:47\n",
      "\n",
      "## Executive Summary\n",
      "Query Type: Comprehensive\n",
      "Time Horizon: Medium\n",
      "Risk Tolerance: Moderate\n",
      "\n",
      "## Research Plan\n",
      "{\n",
      "    \"data_collection_tasks\": [\n",
      "        {\n",
      "            \"task\": \"Gather financial statements and reports for AAPL\",\n",
      "            \"success_criteria\": \"Obtain latest annual and quarterly financial data\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Collect industry reports and competitor analysis\",\n",
      "            \"success_criteria\": \"Identify key competitors and industry trends\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Review analyst reports and forecasts for AAPL\",\n",
      "            \"success_criteria\": \"Understand market expectations and projections\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Assess macroeconomic factors impacting AAPL\",\n",
      "            \"success_criteria\": \"Identify economic trends that may affect the company\"\n",
      "        }\n",
      "    ],\n",
      "    \"analysis_requirements\": {\n",
      "        \"growth_prospects\": \"Conduct a DCF analysis to estimate future cash flows\",\n",
      "        \"competitor_comparison\": \"Perform a SWOT analysis to compare AAPL to competitors\",\n",
      "        \"risk_factors\": \"Conduct a sensitivity analysis to identify key risk factors\"\n",
      "    },\n",
      "    \"risk_assessment_focus_areas\": [\n",
      "        \"Market risk\",\n",
      "        \"Regulatory risk\",\n",
      "        \"Technology risk\",\n",
      "        \"Financial risk\"\n",
      "    ],\n",
      "    \"success_criteria\": {\n",
      "        \"growth_prospects\": \"Determine a growth rate range for the next 2 years\",\n",
      "        \"competitor_comparison\": \"Identify AAPL's competitive advantages and weaknesses\",\n",
      "        \"risk_factors\": \"Highlight the top 3 risk factors impacting AAPL\"\n",
      "    }\n",
      "}\n",
      "\n",
      "## Data Collection Summary\n",
      "Documents processed: 21\n",
      "\n",
      "## Financial Analysis\n",
      "1. Financial health assessment:\n",
      "   - Apple (AAPL) has a strong financial position with a total cash of $55.37 billion and a total debt of $101.70 billion. The company has a quick ratio of 0.724 and a current ratio of 0.868, indicating its ability to meet short-term obligations. The return on assets is 24.55% and the return on equity is 149.81%, reflecting efficient asset utilization and profitability. The gross profit margin is 46.68% and the profit margin is 24.30%, demonstrating solid financial performance.\n",
      "\n",
      "2. Growth prospects and trends:\n",
      "   - Apple has shown consistent growth with a 52-week change of 9.64% and earnings quarterly growth of 9.3%. The company's revenue growth is 9.6% and earnings growth is 12.1%. The forward EPS is expected to increase to $8.31 from the trailing EPS of $6.59, indicating positive growth prospects. The company's free cash flow and operating cash flow are also strong, at $94.87 billion and $108.56 billion respectively.\n",
      "\n",
      "3. Competitive positioning:\n",
      "   - Apple is a market leader in the technology industry, known for its innovative products and strong brand loyalty. The company's enterprise value is $3.84 trillion, making it one of the most valuable companies in the world. Apple's market cap is $377.58 billion, with a strong presence in the global market. The company's price to book ratio is 57.42, reflecting investor confidence in its future growth potential.\n",
      "\n",
      "4. Key opportunities and threats:\n",
      "   - Opportunities: Apple has opportunities for growth in emerging markets, expansion of its services segment, and continued innovation in product development. The company's strong financial position allows it to invest in research and development for future growth.\n",
      "   - Threats: Competition in the technology industry is intense, with rivals constantly innovating and introducing new products. Economic downturns and supply chain disruptions could also pose threats to Apple's business operations.\n",
      "\n",
      "5. Investment recommendation:\n",
      "   - Based on the comprehensive analysis of Apple's financial health, growth prospects, competitive positioning, opportunities, and threats, the recommendation is to BUY the stock. Apple's strong financial performance, growth potential, and market leadership position make it an attractive investment opportunity for medium-term investors. Additionally, the target high price of $310.00 and the current price of $254.43 suggest potential upside for investors.\n",
      "\n",
      "## Risk Assessment (Calculated Scores)\n",
      "- Financial: 7/10\n",
      "- Market: 7/10\n",
      "- Operational: 6/10\n",
      "- Macro: 5/10\n",
      "- Overall: 7/10\n",
      "\n",
      "### Risk Commentary\n",
      "Calculated Risk Scores (Heuristic):\n",
      "{\n",
      "  \"financial\": 7,\n",
      "  \"market\": 7,\n",
      "  \"operational\": 6,\n",
      "  \"macro\": 5,\n",
      "  \"overall\": 7\n",
      "}\n",
      "\n",
      "Metrics:\n",
      "{\n",
      "  \"beta\": 1.109,\n",
      "  \"debt_to_equity\": 1.54486,\n",
      "  \"current_ratio\": 0.868,\n",
      "  \"profit_margin\": 0.24295999,\n",
      "  \"roa\": 0.24545999,\n",
      "  \"roe\": 1.49814,\n",
      "  \"pe_ratio\": 38.608498,\n",
      "  \"volatility\": 0.3262531840147587,\n",
      "  \"max_drawdown\": -0.3336052208070358\n",
      "}\n",
      "\n",
      "Expert Commentary & Mitigations:\n",
      "Financial Risk (Score: 7):\n",
      "Rationale: The company has a high debt-to-equity ratio and a relatively low current ratio, indicating potential financial instability.\n",
      "Mitigation strategies:\n",
      "1. Increase profitability through cost-cutting measures or revenue growth initiatives.\n",
      "2. Refinance debt to lower interest payments and improve liquidity.\n",
      "3. Diversify revenue streams to reduce reliance on a single product or market.\n",
      "4. Implement strict financial controls to monitor and manage cash flow effectively.\n",
      "5. Conduct stress tests to assess the impact of adverse financial scenarios.\n",
      "\n",
      "Market Risk (Score: 7):\n",
      "Rationale: The company's beta and volatility suggest high sensitivity to market fluctuations.\n",
      "Mitigation strategies:\n",
      "1. Hedge against market risks through options or futures contracts.\n",
      "2. Stay informed about market trends and adjust investment strategies accordingly.\n",
      "3. Diversify the investment portfolio to spread risk across different asset classes.\n",
      "4. Monitor competitor activities and industry developments to anticipate market shifts.\n",
      "5. Maintain a long-term perspective to ride out short-term market volatility.\n",
      "\n",
      "Operational Risk (Score: 6):\n",
      "Rationale: The company faces operational challenges that could impact its efficiency and profitability.\n",
      "Mitigation strategies:\n",
      "1. Implement robust internal controls to minimize operational errors and fraud.\n",
      "2. Invest in technology and automation to streamline processes and reduce human error.\n",
      "3. Conduct regular audits and risk assessments to identify and address operational weaknesses.\n",
      "4. Develop a contingency plan to mitigate disruptions in the supply chain or production process.\n",
      "5. Provide ongoing training and development opportunities for employees to enhance operational performance.\n",
      "\n",
      "Macro Risk (Score: 5):\n",
      "Rationale: The company is exposed to macroeconomic factors that could affect its overall performance.\n",
      "Mitigation strategies:\n",
      "1. Stay informed about macroeconomic trends and adjust business strategies accordingly.\n",
      "2. Diversify geographically to reduce reliance on a single market or region.\n",
      "3. Maintain a flexible business model that can adapt to changing economic conditions.\n",
      "4. Monitor government policies and regulations that could impact the business environment.\n",
      "5. Build strong relationships with key stakeholders to navigate macroeconomic challenges effectively.\n",
      "\n",
      "Overall Recommendation:\n",
      "Given the moderate risk tolerance and medium time horizon, it is recommended to closely monitor financial, market, operational, and macro risks. Implementing the suggested mitigation strategies can help mitigate potential risks and improve the company's overall resilience. Consider diversifying the investment portfolio and maintaining a balanced approach to risk management. Regularly review and adjust risk mitigation strategies as needed to align with changing market conditions.\n",
      "\n",
      "## Agent Confidence Scores\n",
      "- Planning: 0.9\n",
      "- Collection: 0.95\n",
      "- Analysis: 0.95\n",
      "- Risk Assessment: 0.95\n",
      "\n",
      "---\n",
      "*This report was generated by an AI-powered investment research assistant. \n",
      "Please conduct additional due diligence before making investment decisions.*\n",
      "\n",
      "📄 Report saved as: research_report_AAPL_20250929_193247.md\n"
     ]
    }
   ],
   "source": [
    "# Now this should work\n",
    "results, report = await run_research_example(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f97672cf-c01d-4aca-aae1-5d8d9849c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Starting research for MSFT\n",
      "INFO:orchestrator:Step 1: Planning research approach\n",
      "INFO:planning_agent:Planning research for MSFT\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestrator:Step 2: Collecting financial data\n",
      "INFO:data_collection_agent:Collecting data for MSFT\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestrator:Step 3: Analyzing collected data\n",
      "INFO:analysis_agent:Analyzing data for MSFT\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestrator:Step 4: Assessing investment risks\n",
      "INFO:risk_assessment_agent:Assessing risks for MSFT\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:orchestrator:Research completed for MSFT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Investment Research Report: MSFT\n",
      "Generated on: 2025-09-29 16:49:12\n",
      "\n",
      "## Executive Summary\n",
      "Query Type: Comprehensive\n",
      "Time Horizon: Medium\n",
      "Risk Tolerance: Moderate\n",
      "\n",
      "## Research Plan\n",
      "{\n",
      "    \"data_collection_tasks\": [\n",
      "        {\n",
      "            \"task\": \"Gather financial reports and statements for Microsoft (MSFT)\",\n",
      "            \"success_criteria\": \"Obtain latest quarterly and annual reports\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Research industry reports on cloud business performance\",\n",
      "            \"success_criteria\": \"Identify trends and growth projections\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Review analyst reports on Microsoft's cloud business\",\n",
      "            \"success_criteria\": \"Understand analyst sentiment and recommendations\"\n",
      "        },\n",
      "        {\n",
      "            \"task\": \"Collect information on key competitors in the cloud business\",\n",
      "            \"success_criteria\": \"Identify market share and competitive positioning\"\n",
      "        }\n",
      "    ],\n",
      "    \"analysis_requirements\": {\n",
      "        \"analysis\": \"Perform financial ratio analysis for Microsoft\",\n",
      "        \"success_criteria\": \"Identify profitability, liquidity, and solvency ratios\"\n",
      "    },\n",
      "    \"risk_assessment_focus_areas\": {\n",
      "        \"focus_areas\": [\n",
      "            \"Regulatory risks in the cloud industry\",\n",
      "            \"Competition risks from other tech giants\",\n",
      "            \"Cybersecurity risks for cloud data\"\n",
      "        ]\n",
      "    },\n",
      "    \"success_criteria\": {\n",
      "        \"overall_success_criteria\": \"Provide a comprehensive analysis of Microsoft's cloud business performance and key risks with actionable recommendations\"\n",
      "    }\n",
      "}\n",
      "\n",
      "## Data Collection Summary\n",
      "Documents processed: 22\n",
      "\n",
      "## Financial Analysis\n",
      "1. Financial Health Assessment:\n",
      "   - Microsoft (MSFT) has a strong financial position with a market capitalization of $3.83 trillion and total cash of $94.56 billion. The company has a low debt-to-equity ratio of 32.66, indicating a healthy balance sheet.\n",
      "   - MSFT has a trailing PE ratio of 37.67 and a forward PE ratio of 34.42, suggesting that the stock may be slightly overvalued based on earnings multiples. However, the company's strong profit margins of 36.15% and return on equity of 33.28% indicate efficient operations and profitability.\n",
      "\n",
      "2. Growth Prospects and Trends:\n",
      "   - Microsoft has shown consistent revenue growth, with a revenue per share of $37.90 and revenue growth of 18.1%. The company's earnings per share (EPS) has also been growing, with a trailing EPS of $13.66 and a forward EPS of $14.95.\n",
      "   - MSFT's earnings and revenue growth rates of 23.7% and 18.1% respectively indicate a positive growth trajectory. The company's strong gross margins of 68.82% and operating margins of 44.90% further support its growth prospects.\n",
      "\n",
      "3. Competitive Positioning:\n",
      "   - Microsoft is a dominant player in the technology industry, with a strong market position in cloud computing, productivity software, and gaming. The company's strong brand and diversified product portfolio give it a competitive edge in the market.\n",
      "   - MSFT's high institutional ownership of 74.57% and strong insider ownership of 0.07% indicate confidence in the company's long-term prospects and stability.\n",
      "\n",
      "4. Key Opportunities and Threats:\n",
      "   - Opportunities: Microsoft has opportunities for growth in cloud computing, artificial intelligence, and digital transformation services. The company's strong cash position allows for investments in research and development to drive innovation.\n",
      "   - Threats: Competition in the technology industry is intense, with rivals like Amazon and Google posing a threat to Microsoft's market share. Regulatory challenges and cybersecurity risks also present potential threats to the company.\n",
      "\n",
      "5. Investment Recommendation:\n",
      "   - Based on the comprehensive analysis of Microsoft's financial health, growth prospects, competitive positioning, and key opportunities and threats, the recommendation for investors is to consider a strong buy position on MSFT stock. The company's solid financials, growth potential, and market position make it a favorable long-term investment option. However, investors should monitor market conditions and industry developments closely to mitigate potential risks.\n",
      "\n",
      "## Risk Assessment\n",
      "1. Financial risks:\n",
      "   - Liquidity risk: (7/10) - Microsoft has a strong cash position, but any unexpected cash outflows or liquidity constraints could impact the company's ability to meet its financial obligations.\n",
      "   - Solvency risk: (8/10) - While Microsoft has a low debt-to-equity ratio and strong profitability, a significant increase in debt levels or a decline in earnings could impact the company's solvency.\n",
      "   - Profitability risk: (6/10) - The slightly overvalued stock price and intense competition in the technology industry could potentially impact Microsoft's profit margins and overall profitability.\n",
      "\n",
      "2. Market risks:\n",
      "   - Volatility risk: (7/10) - Microsoft's stock price may be subject to market volatility, especially given its high market capitalization and exposure to global economic trends.\n",
      "   - Correlation risk: (6/10) - The correlation of Microsoft's stock with broader market indices could impact its performance, especially during market downturns.\n",
      "   - Beta risk: (7/10) - Microsoft's beta of 1.04 indicates that the stock is slightly more volatile than the market average, which could lead to higher fluctuations in its price.\n",
      "\n",
      "3. Operational risks:\n",
      "   - Management risk: (5/10) - Changes in the executive team or strategic missteps could impact Microsoft's operations and financial performance.\n",
      "   - Competition risk: (8/10) - Intense competition in the technology industry, especially from rivals like Amazon and Google, could impact Microsoft's market share and profitability.\n",
      "   - Regulation risk: (6/10) - Regulatory challenges, especially related to data privacy and antitrust issues, could pose risks to Microsoft's business operations.\n",
      "\n",
      "4. Macro-economic risks:\n",
      "   - Interest rate risk: (5/10) - Changes in interest rates could impact Microsoft's borrowing costs and investment decisions.\n",
      "   - Inflation risk: (4/10) - Inflation could erode the purchasing power of Microsoft's cash reserves and impact its financial performance.\n",
      "   - Sector risks: (7/10) - The technology sector is subject to rapid technological advancements and changing consumer preferences, which could impact Microsoft's competitive position.\n",
      "\n",
      "5. Risk mitigation strategies:\n",
      "   - Diversification of revenue streams and product offerings to reduce dependence on any single market or product.\n",
      "   - Continuous monitoring of market trends, competition, and regulatory developments to proactively address potential risks.\n",
      "   - Maintaining a strong cash position and prudent financial management to mitigate liquidity and solvency risks.\n",
      "\n",
      "6. Risk-adjusted recommendation:\n",
      "   - Based on the assessment of financial, market, operational, and macro-economic risks, the recommendation for investors with a moderate risk tolerance and medium time horizon is to consider a buy position on MSFT stock. While there are inherent risks associated with investing in the technology sector, Microsoft's strong financial position, growth prospects, and competitive positioning make it a favorable long-term investment option. Investors should closely monitor market conditions and industry developments to adjust their investment strategy accordingly.\n",
      "\n",
      "## Agent Confidence Scores\n",
      "- Planning: 0.9\n",
      "- Collection: 0.8\n",
      "- Analysis: 0.85\n",
      "- Risk Assessment: 0.8\n",
      "\n",
      "---\n",
      "*This report was generated by an AI-powered investment research assistant. \n",
      "Please conduct additional due diligence before making investment decisions.*\n"
     ]
    }
   ],
   "source": [
    "# Create your own query\n",
    "query = create_research_query(\n",
    "    ticker=\"MSFT\",\n",
    "    query_type=\"comprehensive\",\n",
    "    time_horizon=\"medium\",\n",
    "    risk_tolerance=\"moderate\",\n",
    "    questions=[\"How is the cloud business performing?\", \"What are the key risks?\"]\n",
    ")\n",
    "\n",
    "# Use orchestrator directly\n",
    "orch = InvestmentResearchOrchestrator()\n",
    "results = await orch.conduct_research(query)\n",
    "\n",
    "# Generate & display report\n",
    "report = orch.generate_research_report(query, results)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53519204-f4b8-4f8b-af99-706fd05bd9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
